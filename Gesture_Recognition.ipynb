{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gesture Recognition for Smart TVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import imageio.v2 as imageio\n",
    "import skimage\n",
    "from skimage.transform import resize\n",
    "import datetime\n",
    "import os\n",
    "import cv2\n",
    "import abc\n",
    "from sys import getsizeof\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, BatchNormalization, Activation\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import optimizers\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import random as rn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the random state to replicate the output\n",
    "\n",
    "np.random.seed(30)\n",
    "rn.seed(30)\n",
    "tf.random.set_seed(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the root folder name as base path\n",
    "base_path = 'Project_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelBuilder(metaclass=abc.ABCMeta):\n",
    "    \"\"\"\n",
    "    Abstract base class for building models and data generators.\n",
    "    \"\"\"\n",
    "\n",
    "    def initialize_path(self, base_path):\n",
    "        \"\"\"\n",
    "        Initialize paths for training and validation data.\n",
    "\n",
    "        Args:\n",
    "        - base_path (str): Base directory path containing train.csv and val.csv.\n",
    "\n",
    "        Returns:\n",
    "        - None\n",
    "        \"\"\"\n",
    "        self.train_doc = np.random.permutation(open(base_path + '/' + 'train.csv').readlines())\n",
    "        self.val_doc = np.random.permutation(open(base_path + '/' + 'val.csv').readlines())\n",
    "        self.train_path = base_path + '/' + 'train'\n",
    "        self.val_path = base_path + '/' + 'val'\n",
    "        self.num_train_sequences = len(self.train_doc)\n",
    "        self.num_val_sequences = len(self.val_doc)\n",
    "        \n",
    "    def initialize_image_props(self, image_height=100, image_width=100):\n",
    "        \"\"\"\n",
    "        Initialize properties related to images.\n",
    "\n",
    "        Args:\n",
    "        - image_height (int): Height of the images.\n",
    "        - image_width (int): Width of the images.\n",
    "\n",
    "        Returns:\n",
    "        - None\n",
    "        \"\"\"\n",
    "        self.image_height = image_height\n",
    "        self.image_width = image_width\n",
    "        self.channels = 3\n",
    "        self.num_classes = 5\n",
    "        self.total_frames = 30\n",
    "          \n",
    "    def initialize_hyperparameters(self, number_of_sample_frames=30, batch_size=20, num_epochs=20):\n",
    "        \"\"\"\n",
    "        Initialize hyperparameters for training.\n",
    "\n",
    "        Args:\n",
    "        - number_of_sample_frames (int): Number of sample frames.\n",
    "        - batch_size (int): Batch size for training.\n",
    "        - num_epochs (int): Number of epochs for training.\n",
    "\n",
    "        Returns:\n",
    "        - None\n",
    "        \"\"\"\n",
    "        self.number_of_sample_frames = number_of_sample_frames\n",
    "        self.batch_size = batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "        \n",
    "        \n",
    "    def generator(self, source_path, folder_list, augment=False):\n",
    "        \"\"\"\n",
    "        Generator function for creating batches of data.\n",
    "\n",
    "        Args:\n",
    "        - source_path (str): Path to the source directory containing video frames.\n",
    "        - folder_list (list): List of folders containing video frames.\n",
    "        - augment (bool): Whether to perform data augmentation.\n",
    "\n",
    "        Yields:\n",
    "        - batch_data (numpy array): Batch of input data.\n",
    "        - batch_labels (numpy array): Batch of corresponding labels.\n",
    "        \"\"\"\n",
    "        img_idx = np.round(np.linspace(0, self.total_frames - 1, self.number_of_sample_frames, dtype=int))\n",
    "        batch_size = self.batch_size\n",
    "        \n",
    "        while True:\n",
    "            t = np.random.permutation(folder_list)\n",
    "            num_batches = len(t) // batch_size\n",
    "        \n",
    "            for batch in range(num_batches): \n",
    "                batch_data, batch_labels = self.one_batch_data(source_path, t, batch, batch_size, img_idx, augment)\n",
    "                yield batch_data, batch_labels \n",
    "\n",
    "            remaining_samples = len(t) % batch_size\n",
    "        \n",
    "            if (remaining_samples != 0):\n",
    "                batch_data, batch_labels = self.one_batch_data(source_path, t, num_batches, batch_size, img_idx, augment, remaining_samples)\n",
    "                yield batch_data, batch_labels \n",
    "    \n",
    "    \n",
    "    def one_batch_data(self, source_path, t, batch, batch_size, img_idx, augment, remaining_samples=0):\n",
    "        \"\"\"\n",
    "        Fetch one batch of data.\n",
    "\n",
    "        Args:\n",
    "        - source_path (str): Path to the source directory containing video frames.\n",
    "        - t (list): List of folders containing video frames.\n",
    "        - batch (int): Batch index.\n",
    "        - batch_size (int): Batch size.\n",
    "        - img_idx (numpy array): Indices of frames to be considered.\n",
    "        - augment (bool): Whether to perform data augmentation.\n",
    "        - remaining_samples (int): Number of remaining samples in the last batch.\n",
    "\n",
    "        Returns:\n",
    "        - batch_data (numpy array): Batch of input data.\n",
    "        - batch_labels (numpy array): Batch of corresponding labels.\n",
    "        \"\"\"\n",
    "    \n",
    "        seq_length = remaining_samples if remaining_samples else batch_size\n",
    "    \n",
    "        batch_data = np.zeros((seq_length, len(img_idx), self.image_height, self.image_width, self.channels)) \n",
    "        batch_labels = np.zeros((seq_length, self.num_classes)) \n",
    "    \n",
    "        if (augment):\n",
    "            batch_data_aug = np.zeros((seq_length, len(img_idx), self.image_height, self.image_width, self.channels))\n",
    "\n",
    "        \n",
    "        for folder in range(seq_length): \n",
    "            imgs = os.listdir(source_path + '/' + t[folder + (batch*batch_size)].split(';')[0]) \n",
    "            for idx, item in enumerate(img_idx): \n",
    "                image = imageio.imread(source_path + '/' + t[folder + (batch*batch_size)].strip().split(';')[0] + '/' + imgs[item]).astype(np.float32)\n",
    "                image_resized = resize(image, (self.image_height, self.image_width, 3))\n",
    "            \n",
    "            \n",
    "                # Normalization of RGB channels\n",
    "                batch_data[folder, idx, :, :, 0] = (image_resized[:, :, 0])/255\n",
    "                batch_data[folder, idx, :, :, 1] = (image_resized[:, :, 1])/255\n",
    "                batch_data[folder, idx, :, :, 2] = (image_resized[:, :, 2])/255\n",
    "            \n",
    "                if (augment):\n",
    "                    shifted = cv2.warpAffine(image, \n",
    "                                             np.float32([[1, 0, np.random.randint(-30,30)], [0, 1, np.random.randint(-30, 30)]]), \n",
    "                                            (image.shape[1], image.shape[0]))\n",
    "                    \n",
    "                    gray = cv2.cvtColor(shifted, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                    x0, y0 = np.argwhere(gray > 0).min(axis=0)\n",
    "                    x1, y1 = np.argwhere(gray > 0).max(axis=0) \n",
    "                    \n",
    "                    cropped = shifted[x0:x1, y0:y1, :]\n",
    "                    \n",
    "                    image_resized = resize(cropped, (self.image_height, self.image_width, 3))\n",
    "                    \n",
    "                    M = cv2.getRotationMatrix2D((self.image_width//2, self.image_height//2),\n",
    "                                                np.random.randint(-10,10), 1.0)\n",
    "                    rotated = cv2.warpAffine(image_resized, M, (self.image_width, self.image_height))\n",
    "            \n",
    "                    batch_data_aug[folder, idx, :, :, 0] = (rotated[:, :, 0])/255\n",
    "                    batch_data_aug[folder, idx, :, :, 1] = (rotated[:, :, 1])/255\n",
    "                    batch_data_aug[folder, idx, :, :, 2] = (rotated[:, :, 2])/255\n",
    "                \n",
    "            \n",
    "            batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            \n",
    "    \n",
    "        if (augment):\n",
    "            batch_data = np.concatenate([batch_data, batch_data_aug])\n",
    "            batch_labels = np.concatenate([batch_labels, batch_labels])\n",
    "\n",
    "        \n",
    "        return(batch_data, batch_labels)\n",
    "    \n",
    "    \n",
    "    def train_model(self, model, augment_data=False):\n",
    "        \"\"\"\n",
    "        Train the model.\n",
    "\n",
    "        Args:\n",
    "        - model: Model to be trained.\n",
    "        - augment_data (bool): Whether to augment the training data.\n",
    "\n",
    "        Returns:\n",
    "        - history: Training history.\n",
    "        \"\"\"\n",
    "        train_generator = self.generator(self.train_path, self.train_doc, augment=augment_data)\n",
    "        val_generator = self.generator(self.val_path, self.val_doc)\n",
    "\n",
    "        # Create a directory with model name and current datetime\n",
    "        model_name = 'model_init' + '_' + str(datetime.datetime.now()).replace(' ', '').replace(':', '_') + '/'\n",
    "    \n",
    "        if not os.path.exists(model_name):\n",
    "            os.mkdir(model_name)\n",
    "        \n",
    "        # Generate model file inside the created folder\n",
    "        filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.keras'\n",
    "\n",
    "        # Add model checkpoint\n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', save_freq='epoch')\n",
    "        \n",
    "        # Add learning rate\n",
    "        LR = ReduceLROnPlateau(monitor='val_loss', factor=0.2, verbose=1, patience=4)\n",
    "        callbacks_list = [checkpoint, LR]\n",
    "\n",
    "        # Calculate steps per epoch\n",
    "        if (self.num_train_sequences % self.batch_size) == 0:\n",
    "            steps_per_epoch = int(self.num_train_sequences/self.batch_size)\n",
    "        else:\n",
    "            steps_per_epoch = (self.num_train_sequences//self.batch_size) + 1\n",
    "\n",
    "        if (self.num_val_sequences % self.batch_size) == 0:\n",
    "            validation_steps = int(self.num_val_sequences/self.batch_size)\n",
    "        else:\n",
    "            validation_steps = (self.num_val_sequences//self.batch_size) + 1\n",
    "    \n",
    "        # Fit the model\n",
    "        history = model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=self.num_epochs, verbose=1, \n",
    "                            callbacks=callbacks_list, validation_data=val_generator, \n",
    "                            validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)\n",
    "        return history\n",
    "\n",
    "        \n",
    "    @abc.abstractmethod\n",
    "    def model_definition(self):\n",
    "        \"\"\"\n",
    "        Abstract method for defining the model architecture.\n",
    "        \"\"\"\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(history):\n",
    "    \"\"\"\n",
    "    Plots training and validation loss, as well as categorical accuracy and validation categorical accuracy.\n",
    "\n",
    "    Args:\n",
    "    - history: History object returned by model.fit(), containing training metrics.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,4))\n",
    "    axes[0].plot(history.history['loss'])   \n",
    "    axes[0].plot(history.history['val_loss'])\n",
    "    axes[0].legend(['loss','val_loss'])\n",
    "\n",
    "    axes[1].plot(history.history['categorical_accuracy'])   \n",
    "    axes[1].plot(history.history['val_categorical_accuracy'])\n",
    "    axes[1].legend(['categorical_accuracy','val_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 - CNN with GRU + RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNCNN(ModelBuilder):\n",
    "    \n",
    "    def model_definition(self, cells=64, dense_neurons=64, dropout=0.25):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(TimeDistributed(Conv2D(16, (3, 3), padding='same', activation='relu'),\n",
    "            input_shape=(self.number_of_sample_frames, self.image_height, self.image_width, self.channels)))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "        model.add(TimeDistributed(Conv2D(32, (3, 3), padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "        model.add(TimeDistributed(Conv2D(64, (3, 3), padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "        model.add(TimeDistributed(Conv2D(128, (3, 3), padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "\n",
    "        model.add(GRU(cells))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(dense_neurons, activation='relu'))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(self.num_classes, activation='softmax'))\n",
    "        optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.0002)\n",
    "        model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_cnn = RNNCNN()\n",
    "rnn_cnn.initialize_path(base_path)\n",
    "rnn_cnn.initialize_image_props(image_height=120, image_width=120)\n",
    "rnn_cnn.initialize_hyperparameters(number_of_sample_frames=18, batch_size=20, num_epochs=20)\n",
    "rnn_cnn_model = rnn_cnn.model_definition(cells=128, dense_neurons=128, dropout=0.25)\n",
    "rnn_cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Total Parameters: \", rnn_cnn_model.count_params())\n",
    "model_1 = rnn_cnn.train_model(rnn_cnn_model, augment_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
